owner,repo,topics,readme,created_at,updated_at,language,owner,owner_type,watchers_count,stargazers_count,forks_count,commits_count,default_branch,contributors,contributors_count,releases_count,tags_count,open_issues_count,closed_issues_count,open_pr_count,closed_pr_count
kakao,DAFT,n/a,DAFT Code for the NeurIPS 2019 paper Learning Dynamics of Attention Human Prior for Interpretable Machine Reasoning Dataset Preparation For both CLEVR and GQA we generally followed Hudson et al https github com stanfordnlp mac network However pytorch does not have thread safe dataloader for hdf5 file So we split the hdf5 into single files for faster training and thread safe data loading CLEVR will space about 95GB after extraction features 75GB images 18GB annots misc 2GB GQA will space about 140GB after extraction features 115GB images 21GB annots misc 4GB CLEVR 1 Download CLEVR dataset skip this step if you don t need visualization export DATASETROOT Whatever you want cd DATASETROOT wget https dl fbaipublicfiles com clevr CLEVRv1 0 zip unzip CLEVRv1 0 zip mv CLEVRv1 0 clevr 2 Download preprocessed features and annotations follow Hudson et al https github com stanfordnlp mac network if you want preprocess images and annotations for yourself cd DATASETROOT clevr wget O features tar gz https www dropbox com s sis6lmrrx0ze3z1 features tar gz dl 0 wget O annots tar gz https www dropbox com s 5rto93ddayol949 annots tar gz dl 0 tar xvzf features tar gz tar xvzf annots tar gz GQA 1 Download GQA images skip this step if you don t need visualization export DATASETROOT Whatever you want cd DATASETROOT mkdir gqa cd gqa wget https nlp stanford edu data gqa images zip unzip images zip 2 Download preprocessed features and annotations follow instructions of Hudson et al https github com stanfordnlp mac network tree gqa if you want preprocess images and annotations for yourself cd DATASETROOT gqa wget O features tar gz https www dropbox com s ag0te9o56pz30jk features tar gz dl 0 wget O annots tar gz https www dropbox com s t6bhts8g3xkslyu annots tar gz dl 0 tar xvzf features tar gz tar xvzf annots tar gz Code For reproducibility of our work we employed experimentation framework Sacred https github com IDSIA sacred and followed their command line interface https sacred readthedocs io en latest commandline html Requirements Python 3 6 for f string https www python org dev peps pep 0498 Pytorch 1 2 0 See requirements txt for the rest Training python train py with datasetname root datasetroot usedaft True False maxstep step ex python train py with clevr root DATASETROOT usedaft True maxstep 4 ex python train py with gqa root DATASETROOT usedaft False maxstep 5 For every epoch model weights will be saved at result model daftmac macclevr gqastepmaxsteploadseed Evaluation and Visualization Put the model weight into result model daftmac macclevr gqastepmaxsteploadseed e g result model daftmacgqastep4387678158 checkpoint19 model and run Evaluation python evaluation py with datasetname root datasetroot usedaft True False maxstep step loadseed seed ex python evaluation py with clevr root DATASETROOT usedaft False maxstep 2 loadseed 608494298 ex python evaluation py with gqa root DATASETROOT usedaft True maxstep 12 loadseed 305083948 Visualization python visualize py with datasetname root datasetroot usedaft True False maxstep step loadseed seed ex python visualize py with clevr root DATASETROOT usedaft False maxstep 2 loadseed 608494298 ex python visualize py with gqa root DATASETROOT usedaft True maxstep 12 loadseed 305083948 Citation If you use any part of this code for your research please cite our paper https arxiv org abs 1905 11666 inproceedingskim2019learning title Learning Dynamics of Attention Human Prior for Interpretable Machine Reasoning author Kim Wonjae and Lee Yoonho booktitle Advances in Neural Information Processing Systems NeurIPS year 2019 Contact for Issues Wonjae Kim dandelin kim kakaocorp com Yoonho Lee eddy l kakaocorp com References Opensources 1 MAC Network Paper https arxiv org abs 1803 03067 Author s Code https github com stanfordnlp mac network tree master 2 GQA Paper https arxiv org abs 1902 09506 Author s Code https github com stanfordnlp mac network tree gqa 3 Neural ODE ODE solvers Paper https arxiv org abs 1806 07366 Author s Code https github com rtqichen torchdiffeq License This software is licensed under the Apache 2 license LICENSE quoted below Copyright 2019 Kakao Corp Licensed under the Apache License Version 2 0 the License you may not use this project except in compliance with the License You may obtain a copy of the License at http www apache org licenses LICENSE 2 0 Unless required by applicable law or agreed to in writing software distributed under the License is distributed on an AS IS BASIS WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express or implied See the License for the specific language governing permissions and limitations under the License,2019-10-01T05:09:09Z,2019-12-03T11:02:43Z,Python,kakao,Organization,8,20,2,5,master,dandelin,1,0,0,1,0,1,0
sangam-iss,IRS-MR-RS-2019-07-01-Sangam-Travel-Strategist,n/a,Project Title Itinerary Planner Personalised Travel Strategist Executive Summary Expert Systems are a combination of computer programming and data to imitate human expertise in narrow business domains According to Wikipedia in artificial intelligence an expert system is a computer system that emulates the decision making ability of a human expert Expert systems are designed to solve complex problems by reasoning through bodies of knowledge represented mainly as ifthen rules rather than through conventional procedural code The error rate of a successful expert system is low sometimes much lower than the human error rate for the same task They are very good in capturing very complex patterns which cannot be captured by data mining We have identified the necessity of building an expert system to recommend places and attractions to Singapore Tourists Tourism is one of the fastest growing sectors in Singapore According to 2018 Q4 report of Singapore Tourism Board tourism sector achieved record highs in International Visitor Arrivals and Tourism receipts for the third year consecutively Around 18 5 million visitors visited Singapore in 2018 and it accounted for Tourism Receipts of S 26 9 billion m Due to the rapid growth of this sector tourists can easily be overwhelmed with the options they have In order to facilitate further growth in this sector and help the tourists we have developed an expert system application which can recommend attractions to tourists based on their interests In addition to that it also provides an optimized tour itinerary based on user interests Project Individual Contribution Name Student Number Contribution Email Santhosh Kumar Mohan A0198528L Brainstorming Design OptaPlanner Implementation SpringBoot Implementation Testing Google Map API santhoshmohan u nus edu mailto santhoshmohan u nus edu Gautham Balasubramanian A0198479B Brainstorming Design CLIPS programming Django web application development using BootStrap Integration of different parts gautham u nus edu mailto gautham u nus edu Mercedes Premalatha Ramesh A0198411A Brainstorming CLIPS design Distance Matrix Generation Data Collection Data Cleaning Testing Documentation Video Preparation mercedes u nus edu mailto mercedes u nus edu Video Presentation Please refer to the below URL for Video Report Video Report https www youtube com watch v fSansDYfthE User Installation Guide Please refer to the below URL for the User Installation Guide Installation Guide https github com sangam iss iss mrrs blob master Project 20Report installationguide pdf Project Report Please download the Project Report from below URL Project Report https github com sangam iss iss mrrs blob master Project 20Report Project 20Report pdf,2019-09-21T19:19:38Z,2019-09-26T02:41:38Z,CSS,sangam-iss,User,2,1,2,9,master,sangam-iss#gauthambalasubramanian#santhoshmohan05,3,0,0,0,0,0,0
IBM,mi-visual-reasoning-pubs,n/a,mi visual reasoning pubs publications of the machine intelligence team,2019-10-21T14:45:47Z,2019-12-08T20:48:24Z,TeX,IBM,Organization,5,1,1,490,master,tsjayram#vmarois#tkornuta-ibm#vincentalbouy#ahmetsozcan#stevemar,6,0,1,1,0,1,0
MiuLab,FlowDelta,machine-comprehension#nlp#pytorch#question-answering,FlowDelta Modeling Flow Information Gain in Reasoning for Conversational Machine Comprehension An implementation of the FlowDelta Modeling Flow Information Gain in Reasoning for Conversational Machine Comprehension https arxiv org abs 1908 05117 CodaLab pages submitted to public leaderboard QuAC https worksheets codalab org worksheets 0xacb00235ee6b42b3aa682c5d62204a81 CoQA https worksheets codalab org worksheets 0xc38eeb86a2b34bceace033fabd531f22 As there are large differences between the usage of FlowDeltaQA and BertFlowDelta we place the usage seperately in the corresponding directory Reference Main paper to be cited inproceedingsyeh2019flowdelta title FlowDelta Modeling Flow Information Gain in Reasoning for Conversational Machine Comprehension author Yeh Yi Ting and Chen Yun Nung booktitle Proceedings of the 2nd Workshop on Machine Reading for Question Answering pages 86 90 year 2019,2019-08-14T13:06:23Z,2019-12-06T16:14:32Z,Python,MiuLab,Organization,2,15,6,10,master,exe1023#yvchen,2,0,0,1,7,0,0
Bassem-Makni,NMT4RDFS,deep-learning#deep-neural-networks#graph-words#nmt#nmt-model#noise-tolerance#rdf#rdfs#reasoning#semantic-web#sparql,NMT4RDFS Neural Machine Translation for RDFS reasoning code and datasets for Deep learning for noise tolerant RDFS reasoning http www semantic web journal net content deep learning noise tolerant rdfs reasoning 4 Setting up environment Create a virtual environment with python 3 If using conda 1 with GPU run conda create n nmt4rdfs python 3 7 tensorflow gpu 2 without GPU run conda create n nmt4rdfs python 3 7 tensorflow Activate environment using conda activate nmt4rdfs Install requirements pip install r requirements txt Creating graph words for LUBM1 dataset The first step to create the graph words is to collect the global resources i e classes properties and properties groups as discussed in the paper You can either 1 Load the LUBM ontology from http swat cse lehigh edu onto univ bench owl into the repository specified in config json In this case the SPARQL queries defined in code sparql are going to be used to collect the global resources 2 Use the pre computed LUBM global resources from data lubm1intact globalresources mkdir p data lubm1intact encoding cp data lubm1intact globalresources data lubm1intact encoding Generate the LUBM1 graph words using bash createlubmgraphwords sh Training phase To train the graph words neural machine translator for LUBM1 using the configuration parameters at config json run cd code python trainlubm py Inference phase To use the latest trained model for inference use python inferlubm py inputgraph data lubm1intact graphswithdescriptions HTTPwww Department0 University0 eduAssistantProfessor0 nt You can specify a different model using modelpath Future updates Instructions for generating graph words and training for the Scientists dataset Instructions to customize config json for your dataset,2019-04-22T18:19:32Z,2019-11-22T16:31:00Z,Python,Bassem-Makni,User,1,7,1,25,master,Bassem-Makni,1,0,0,0,0,0,0
langway,Nvwa,ai#artificial-intelligence#gai#nlu#understanding#understanding-computation,Nvwa Nvwa Brain is a AGI Artificial General Intelligence AI also include weak intelligence such as deep leaning etc based on understanding system that can truly realize machine thinking The goal is to create a machine thinking like human beings that can learn and think and help people do things An understandable world similar to human beings can further form the results of logical reasoning association emotion and even humor that other technologies can not achieve Readme https github com langway Nvwa blob master README CN md First why is it called Nvwa Nvwa is the goddess of earth and human creation in Chinese mythology The reason why human beings are human is that they have a wise brain Naming the project Nvwa is the hope that the project will enable the machine to think like human beings Second Construction of operation environment 1 Database 1 The database uses Postgre After installation the postgre user password is set to 123456qaz You can also change the database user and password in trunkloongtiannvwasettings py 2 Install the database build three new databases auth Nvwa currently nvwa2 yiya and restore three databases under the databasebackup directory in the current project 2 python 1 Currently using version Python 3 7 the migration from Python 2 7 is completedFirst Comit edition is python2 7 2 Modify the log code in Python library otherwise it will report an error See below for specific modifications 3 Install the required libraries open the loongtian util pip directory run pipInstallAll py need pytz and other libraries in the early stage check after installation generally no successful installation does not affect the operation Third Running Basic Code 1 Start Nvwa brain run debug loongtian nvwa central Brain Runer py 1 The system will ask whether to delete the original data as shown below In the default debugging state it is suggested to delete the data so as to test the correctness of the system association Image text https raw githubusercontent com langway Nvwa master doc img start nvwa del db png 2 After the start up is completed the following should be done Image text https raw githubusercontent com langway Nvwa master doc img start nvwa success png 2 Start the I O console client Run debug loongtian nvwa adminConsoleRunner py Image text https raw githubusercontent com langway Nvwa master doc img start console png 1 Input user name and password will be required The default user name of the system is Nvwa and password is 123 You can log in The login interface is as follows Image text https raw githubusercontent com langway Nvwa master doc img start console logon png 2 Try to input simple sentences such as cow and cow has legs The results are as follows 3 In the case of development the test nvwa testBrain py can be used directly to run the test Meaning function to view the running results line by line Image text https raw githubusercontent com langway Nvwa master doc img console dialog3 png Fourth Operation of Web Page Form 1 Start the Nvwa central brain first see 3 1 2 Start http server run debug loongtian fuxi http Server Runner py The interface after startup is as follows login as a superuser at present Image text https raw githubusercontent com langway Nvwa master doc img start web server png 3 After starting the server use the browser to open the web address http 127 0 0 1 1547 The interface is as follows Image text https raw githubusercontent com langway Nvwa master doc img start web index page png Notice By default the interface displays the traditional search engine style which can be changed by the left button such as default fit full screen 4 You can enter some simple sentences and click the Send button to view the results line by line Image text https raw githubusercontent com langway Nvwa master doc img web dialog0 png Image text https raw githubusercontent com langway Nvwa master doc img web dialog1 png Fifth Theory Based on Understanding Basic Part 1 On Metadata Actual Objects 2 On Top Relations 3 About T shaped Data Structure T shaped Data Structure 4 The Hierarchical Structure of Meaning 5 About Action 1 Simple action 2 Conjugate action 3 Context action 4 Internal and External Relevant Action Currently you can read doc Relations between Objects doc Sixth Why open source 1 It has been a long time to do this project From 2006 theoretical exploration has been started and has been going on till now 2 At present AI on the market is inclined to perceptual computing Image and sound are popular through deep learning technology In terms of words especially cognitive computing which can understand meaning like human beings it is also very retarded and deep learning can not solve the problem of artificial general intelligence 3 Once set up a company but finally because of the broken capital chain of investors failed to survive to the end not my fault My heart has been holding a fire I hope that my technology through open source can see the sun again rather than buried in my personal computer hard disk Seventh Hope 1 More people of insight can join in and explore the development direction of strong artificial intelligence together 2 Achieve further breakthroughs in technology at an early date The current version only belongs to the core version of the foundation It only develops the semantics and simple actions There are more technologies to be explored and perfected 3 Develop a commercial version as soon as possible Eighth Other 1 Python library changes Liblogginginit pyLogRecord getMessage if self args msg msg self args if self args try msg msg self args except pass Liblogginghandlers class RotatingFileHandler BaseRotatingHandler def doRollover self def doRollover self Issue 18940 A file may not have been created if delay is True if os path exists self baseFilename os rename self baseFilename dfn Issue 18940 A file may not have been created if delay is True if os path exists self baseFilename try os rename self baseFilename dfn except pass Ninth Contact information mobile phone Wechat 15640193617 Ten Questions 1 Python 3 0 is more slower than Python 2 0,2019-05-30T11:03:56Z,2019-11-27T13:15:02Z,Python,langway,User,2,3,1,35,master,langway,1,1,1,0,1,0,0
robertson809,MachineReasoning_FinalProject,n/a,404 Not Found,2019-04-24T21:02:58Z,2019-10-16T06:26:31Z,Python,robertson809,User,0,1,0,20,master,robertson809,1,0,0,0,0,0,0
stanfordnlp,mac-network,attention#clevr#compositional-attention-networks#machine-reasoning#question-answering#tensorflow#vqa,Compostional Attention Networks for Real World Reasoning Drew A Hudson Christopher D Manning Please note We have updated the GQA challenge https visualreasoning net challenge html deadline to be May 15 Best of Luck This is the implementation of Compositional Attention Networks for Machine Reasoning https arxiv org pdf 1803 03067 pdf ICLR 2018 on two visual reasoning datasets CLEVR dataset http cs stanford edu people jcjohns clevr and the New GQA dataset https visualreasoning net CVPR 2019 https visualreasoning net gqaPaper pdf We propose a fully differentiable model that learns to perform multi step reasoning See our website https cs stanford edu people dorarad mac and blogpost https cs stanford edu people dorarad mac blog html for more information about the model In particular the implementation includes the MAC cell at maccell py maccell py The code supports the standard cell as presented in the paper as well as additional extensions and variants Run python main py h or see config py config py for the complete list of options The adaptation of MAC as well as several baselines for the GQA dataset are located at the GQA branch Bibtex For MAC inproceedingshudson2018compositional title Compositional Attention Networks for Machine Reasoning author Hudson Drew A and Manning Christopher D journal International Conference on Learning Representations ICLR year 2018 For the GQA dataset articlehudson2018gqa title GQA A New Dataset for Real World Visual Reasoning and Compositional Question Answering author Hudson Drew A and Manning Christopher D journal Conference on Computer Vision and Pattern Recognition CVPR year 2019 Requirements Tensorflow originally has been developed with 1 3 but should work for later versions as well We have performed experiments on Maxwell Titan X GPU We assume 12GB of GPU memory See requirements txt requirements txt for the required python packages and run pip install r requirements txt to install them Pre processing Before training the model we first have to download the CLEVR dataset and extract features for the images Dataset To download and unpack the data run the following commands bash wget https dl fbaipublicfiles com clevr CLEVRv1 0 zip unzip CLEVRv1 0 zip mv CLEVRv1 0 CLEVRv1 mkdir CLEVRv1 data mv CLEVRv1 questions CLEVRv1 data The final command moves the dataset questions into the data directory where we will put all the data files we use during training Feature extraction Extract ResNet 101 features for the CLEVR train val and test images with the following commands bash python extractfeatures py inputimagedir CLEVRv1 images train outputh5file CLEVRv1 data train h5 batchsize 32 python extractfeatures py inputimagedir CLEVRv1 images val outputh5file CLEVRv1 data val h5 batchsize 32 python extractfeatures py inputimagedir CLEVRv1 images test outputh5file CLEVRv1 data test h5 batchsize 32 Training To train the model run the following command bash python main py expName clevrExperiment train testedNum 10000 epochs 25 netLength 4 configs args txt First the program preprocesses the CLEVR questions It tokenizes them and maps them to integers to prepare them for the network It then stores a JSON with that information about them as well as word to integer dictionaries in the CLEVRv1 data directory Then the program trains the model Weights are saved by default to weights expName and statistics about the training are collected in results expName where expName is the name we choose to give to the current experiment Notes The number of examples used for training and evaluation can be set by trainedNum and testedNum respectively You can use the r flag to restore and continue training a previously pre trained model We recommend you to try out varying the number of MAC cells used in the network through the netLength option to explore different lengths of reasoning processes Good lengths for CLEVR are in the range of 4 16 using more cells tends to converge faster and achieves a bit higher accuracy while lower number of cells usually results in more easily interpretable attention maps Model variants We have explored several variants of our model We provide a few examples in configs args2 4 txt For instance you can run the first by bash python main py expName experiment1 train testedNum 10000 epochs 40 netLength 6 configs args2 txt args2 configs args2 txt uses a non recurrent variant of the control unit that converges faster args3 configs args3 txt incorporates self attention into the write unit args4 configs args4 txt adds control based gating over the memory See config py config py for further available options Note that some of them are still in an experimental stage Evalutation To evaluate the trained model and get predictions and attention maps run the following bash python main py expName clevrExperiment finalTest testedNum 10000 netLength 16 r getPreds getAtt configs args txt The command will restore the model we have trained and evaluate it on the validation set JSON files with predictions and the attention distributions resulted by running the model are saved by default to preds expName In case you are interested in getting attention maps getAtt and to avoid having large prediction files we advise you to limit the number of examples evaluated to 5 000 20 000 Visualization After we evaluate the model with the command above we can visualize the attention maps generated by running bash python visualization py expName clevrExperiment tier val Tier can be set to train or test as well The script supports filtering of the visualized questions by various ways See visualization py visualization py for further details To get more interpretable visualizations it is highly recommended to reduce the number of cells to 4 8 netLength Using more cells allows the network to learn more effective ways to approach the task but these tend to be less interpretable compared to a shorter networks with less cells Optionally to make the image attention maps look a little bit nicer you can do the following using imagemagick https www imagemagick org for x in preds clevrExperiment Img png do magick convert x brightness contrast 20x35 x done Thank you for your interest in our model Please contact me at dorarad cs stanford edu for any questions comments or suggestions,2018-04-14T03:14:11Z,2019-12-13T11:25:03Z,Python,stanfordnlp,Organization,34,388,97,69,master,dorarad#djdongjin#kamalkraj#drtonyr,4,0,0,8,27,0,8
ibm-watson-embedded-business-assistant,eba-example-agents,ai#anomalydetection#assistant#autonomic-computing#bpm#chatbot#reasoning,This is not a chatbot This is EBA Business Assistant Digital Twin Business Process AI top down RPA BPU BPA whatever you call it by engineers need the best techniques in order to bring valuable AI to their customers EBA presents a unique and proven model based on modern patent pending approaches to machine reasoning The Embedded Business AI EBA framework is an open hybrid multi cloud deployable omni channel enterprise class digital AI framework used by developers to enable advanced domain specific process automation RPA use cases for business users Unlike other dialog management systems that use rule based reasoning and predicate logic with EBA you describe your business domain to the machine in a simple consistent complete and straightforward way Dialog whether human machine or machine machine interaction are simply inputs to and outputs from the reasoning core In other words this is not a chatbot Watson Marketing Assistant powered by EBA assets img ebawmascreenshot png Watson Marketing Assistant powered by EBA assets img ebawmascreenshot png What can you do with EBA In the video below see how IBM used EBA to create an omni present digital twin for marketing professionals that supports its human counterpart wherever she may conduct business IBM Watson Marketing https img youtube com vi KlavNwVEEuU 0 jpg https www youtube com watch v KlavNwVEEuU We also have sample agents for other domains like Supply Chain within the dev lab https eba ibm com assistant lab for you to dig into Contributing This is the public home of the Embedded Business AI framework EBA Please log issues https github com ibm watson embedded business assistant eba example agents issues you encounter with EBA and if you have a contribution please submit a pull request https github com ibm watson embedded business assistant eba example agents pulls Usage Developers feel free to explore EBA build your AI experiences and share with your work colleagues and friends When it comes time for you to release to production please contact us https github com osidorkin and well help get you over the line Services include developer integration support service level agreements and access to the latest AI contributions from our staff and partners License EBA is a framework constructed and operated by the EBA platform engineering team at IBM This repository hosts documentation and sample configurations that work with the EBA core platform This content is licensed under the Apache 2 0 license Full license text is available in LICENSE LICENSE,2018-07-09T18:03:48Z,2019-12-10T19:28:38Z,CSS,ibm-watson-embedded-business-assistant,Organization,8,7,21,822,master,osidorkin#kevingrozav#sbatin#meaganjohnson#arsu77#elahexyz#carstenmichel#Conner1341#louisroehrs#abbasally5#ChristopherNoessel-IBM,11,0,0,3,3,1,16
MikeMpapa,CogBeacon-MultiModal_Dataset_for_Cognitive_Fatigue,n/a,Paper Citation Papakostas Michalis Akilesh Rajavenkatanarayanan and Fillia Makedon CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue Technologies 7 2 2019 46 articlepapakostas2019cogbeacon title CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue author Papakostas Michalis and Rajavenkatanarayanan Akilesh and Makedon Fillia journal Technologies volume 7 number 2 pages 46 year 2019 publisher Multidisciplinary Digital Publishing Institute CogBeacon A Multi Modal Dataset for Modeling Cognitive Fatigue CogBeacon is a multi modal dataset designed to target the effects of cognitive fatigue in human performance The dataset consists of 76 sessions collected from 19 male and female users performing different versions of the Wisconsin Card Sorting Test WCST a popular cognitive test in experimental and clinical psychology designed to assess cognitive flexibility reasoning and specific aspects of cognitive functioning During each session we record and fully annotate user s EEG functionality facial keypoints real time self reports on cognitive fatigue as well as detailed information of the performance metrics achieved during the cognitive task success rate response time number of errors etc Along with the dataset we provide a baseline Machine Learning analysis towards predicting cognitive fatigue and our multi modal implementation of the WCST to allow other researches expand or modify the functionalities of the CogBeacon data collection framework To our knowledge this is the first multi modal dataset specifically designed to assess cognitive fatigue CogBeacon Data Collection Platform can be found The WCST Interface https github com MikeMpapa CogBeacon WCSTinterface Dataset Details As mentioned above the dataset consists of 4 folders EEG facekeypoints fatigueselfreport and userperformance Below we explain the contents of each folder and the way the data is organized Please refer to our paper CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue insert link to publication for more details about the dataset and data collection methodology 1 EEG Data Filename structure There are 76 sessions and data from each session is stored in a separate folder This folder is named user For example the folder name user0vm implies the folder belongs to user with ID 0 using the visual stimuli and that data were collected by a modified version of the WCST task V1 or V2 If the userid is a single integer and the game mode is characterised by the letter m it means that data were recorder using the V1 WCST version If userid is followed by the letter b and the game mode is characterised as m it means that the folder contains data captured using V2 version of the WCST Finally if game mode is characterised by the letter o it means that data collection was based on replicating the rules of the original WCST Bellow are explained the values of the different flags in detail UserID if ID data were collected in the first day of data collection and IF GameMode m WCST V1 if IDb data were collected in the second day of data collection and IF GameMode m WCST V2 StimuliType v visual t textual a auditory GameMode o simulation of the original WCST test m modified version of the WCST Each of these folders consists of individual files collected during each round ie a single answer provided by the user The file name encoding is as follows For example file 317 containes the data captured during the 17th round of the game which was the 3rd round under the same decision rule The EEG Data was recorded using the Muse EEG headset https choosemuse com The headset has four electrodes two over the prefrontal lobe and two behind the ears The data set consists of Raw EEG at a sampling frequency of 220 Hz Absolute Frequency Bands A gamma 32 100 Hz gamma beta 13 32 Hz beta alpha 8 13 Hz alpha theta 4 8 Hz theta and delta 0 5 4Hz delta at sampling frequency of 10 Hz The absolute band power for a given frequency range is the logarithm of the sum of the Power Spectral Density of the EEG data over that frequency range where flow and fhigh are the minimum and maximum frequencies of frequency band x and G is the FFT of the raw EEG signal g Relative Frequency Bands R gamma beta alpha theta and delta at sampling frequency of 10 Hz The relative band powers are calculated by dividing the absolute linear scale power in one band over the sum of the absolute linear scale powers in all bands where x is one of the five frequency bands Session Score for each Frequency band S A value computed by comparing the current value f a band power to its history in sampling frequency of 10 Hz This value is mapped to a score etween 0 and 1 using a linear function that returns 0 if the current value is equal to or below the 10th percentile of the distribution of band powers and returns 1 if its equal to or above the 90th percentile Linear scoring between 0 and 1 is done for any value between these two percentiles Signal Quality Indicator An integer value from 1 optimal quality to 4 very bad quality 2 Facial Keypoints To capture behavioral changes during the task we also recorded variations in the movement of the face capturing a set of 68 facial keypoints and four corners for bounding box with a webcam placed on top of the screen at a frame rate of 2 FPS To identify facial keypoints we deployed the method presented by Kazemi et al http openaccess thecvf com contentcvpr2014 papers KazemiOneMillisecondFace2014CVPRpaper pdf that uses a Regression Tree approach and can be applied in a real time Filename structure This data can be found in a folder named facekeypoints Similar to the EEG dataset there are 76 sessions and data from each session is stored in a separate folder The name of these folders follow the same naming as explained above The last flag in the filename indicates the frameID Thus each filename has a name structure as The facial keypoints and the corners of the bounding box are stored in a numpy npz For example file named 113 npz indicates that it contains the keypoints captured in the third frame of the session which bellonged in the 1st round of the game which was also the 1st round under the same decision rule 3 Fatigue self report During each session participants were told to report when they were having trouble to keep up with the task by pressing a button placed in front of them The button could be pressed at any time during a game as many times as the participants felt appropriate Filename structure This data can be found in the folder named fatigueselfreport The self reports are stored as csv files for each session and the name of these files follow the same structures as the eeg session folders and facial keypoints session folders Each record in the csv indicates how the total number of times a user has pressed the button at this specific point of the game Each row of the csv corresponds to a game round For example an a value of 3 in row 50 means that in that until the 50th round the user had pressed the button 3 times 4 User Performance For every round of every session the system logs a set of metrics and scores related to user performance with respect to the task For each session user performance metrics are stored as a csv and each file follows he same naming convention as the other type of data with an additional metric at the end of the filename indicating the total score of the user at the end of the game computed by summing the individual user scores at each round The formula for estimating user scores at each round can be found bellow Each record of the csv consists of the following metrics Round Number An integer value indicating the current round Question number An integer value indicating the current question number under a specific rule type Level An integer value indicating the current level of the test It indicates number of possible choices offered by the system 2 3 4 or 5 Score An indicative round based user score computed as Stimuli The type of the correct stimuli color shape or number Stimuli Type The value of the correct stimuli If color green yellow blue red or magenta If shape triangle star cross circle or heart If number one two three four or five Response A binary flag that indicating if user response was correct in a given round Time Users response time at every round in seconds Correct The total number of correct answers NON PER Errors The cumulative number of non perseverative errors until the current round Non perseverative errors are the errors recorded when the user tries to figure out the new rule after a rule change Given that there were three possible decision rules in total based on color or shape or number a user is supposed to figure out the correct rule no later than the third round after a rule change Any error that occurred before the third round is considered as non perseverative error PER Errors The cumulative number of perseverative errors until the current round Perseverative errors are when the user continues to apply the wrong rule despite the informative feedback provided by the system Source code ML analysis The code and the data splited into 10 Folds for cross validation that we used for the ML analysis in our papaer CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue can be found HERE https www dropbox com sh 1i49we8usl3bma0 AAC5O2peccM7tzMMiqjVRnZza dl 0 Details about the EEG data codes used in python can be found HERE https github com MikeMpapa CogBeacon MultiModalDatasetforCognitiveFatigue issues 1 Confidentiality Data Sharing Our team has received permission by the Institutional Review Board IRB of the University of Texas at Arlington UTA in order to conduct these experiments and share the attached data CogBeacons protocols ID is 2019 0253 and its title is CogBeacon Towards detecting cognitive fatigue Main contributors of this study are Mr Michalis Papakostas PI michalis papakostas mavs uta edu Mr Akilesh Rajavenkatanarayanan CO PI akilesh rajavenkatanarayanan mavs uta edu and Dr Fillia Makedon Faculty Advisor makedon uta edu For additional information or questions about the confidentiality or data sharing protocol please feel free to contact directly the IRB office at UTA erahelpdesk uta edu or to the project personnel Available in the repo is a copy of the consent form that the participants had to sign Paper Citation Papakostas Michalis Akilesh Rajavenkatanarayanan and Fillia Makedon CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue Technologies 7 2 2019 46 articlepapakostas2019cogbeacon title CogBeacon A Multi Modal Dataset and Data Collection Platform for Modeling Cognitive Fatigue author Papakostas Michalis and Rajavenkatanarayanan Akilesh and Makedon Fillia journal Technologies volume 7 number 2 pages 46 year 2019 publisher Multidisciplinary Digital Publishing Institute,2019-02-26T22:35:14Z,2019-11-26T04:00:36Z,n/a,MikeMpapa,User,3,3,2,59,master,akileshrajan#MikeMpapa,2,0,0,0,1,0,0
ducminhkhoi,MAC_Network,n/a,This is the Pytorch Implementation of Compositional Attention Networks for Machine Reasoning https arxiv org abs 1803 03067 1 Download and extract CLEVR dataset from https cs stanford edu people jcjohns clevr https cs stanford edu people jcjohns clevr then put it in folder data 2 Create folder weights to store snapshot of the model while training 3 Read the argparse part in main py for more options and run python main py to get the result of default setting,2018-04-16T16:29:05Z,2019-05-03T07:27:44Z,Python,ducminhkhoi,User,1,2,2,3,master,ducminhkhoi,1,0,0,2,0,0,0
MelechMaglasang,hw3,n/a,404 Not Found,2019-02-22T19:38:36Z,2019-03-02T22:50:12Z,Java,MelechMaglasang,User,0,1,0,17,development,MelechMaglasang,1,0,0,0,0,0,0
StuartCHAN,implementation_for_machine_reading_and_strategique_reasoning,artificial-intelligence#natural-language-processing,The implementation for machine reading and strategique reasoning For a given professional article through machine reading it is required to be able to locate analyze and reason the answers to specific questions in the text The problem covers six types factual questions list type questions definition type questions opinion type questions and text type questions The principle is to let the machine read the above 6 types of questions and generate answers The matching degree of the answers with the standard answers is evaluated using the ROUGE L and BLEU indicators For the usage and the results of data all rights reserved to the organiser This implementation is inspired by Google s QANet https openreview net pdf id B14TlG RW and the blog https medium com minsangkim implementing question answering networks with cnns 5ae5f08e312b Dataset The basic data collection is originally provided by China Electronics Technology Group Corporation No 28 Research Institute exclusively for participants engaged Requirements Python 2 7 NumPy tqdm TensorFlow 1 5 spacy 2 0 9 bottle Usage To preprocess the data run bash preprocess the data python config py mode prepro This procedure of processing is learned from R Net by HKUST KnowComp https github com HKUST KnowComp R Net hyper parameters are stored in config py To debug train test demo run bash python config py mode debug train test demo To evaluate the trained model with the code provided by the organiser run bash python testcommon py data modelname json train modelname answer answer json The default directory for the tensorboard log file is train modelname event,2018-11-17T11:35:06Z,2018-11-18T05:46:34Z,Python,StuartCHAN,User,1,1,0,5,master,StuartCHAN,1,0,0,0,0,0,0
ushagayatri,ushalokala,n/a,404 Not Found,2019-03-13T20:24:14Z,2019-07-18T22:49:38Z,n/a,ushagayatri,User,0,1,0,2,master,ushagayatri,1,0,0,0,0,0,0
vermouth1992,CSCI699ml4know,deep-learning#deep-reinforcement-learning#named-entity-recognition#natural-language-processing#relation-extraction#sentiment-analysis,CSCI699ml4know CSCI 699 Machine Learning for Knowledge Extraction amp Reasoning Spring 2019 Homework,2019-02-02T06:54:57Z,2019-05-05T22:30:23Z,Python,vermouth1992,User,0,1,1,74,master,vermouth1992,1,0,0,0,0,0,0
priyanksharma7,Artificial-Intelligence,n/a,Artificial Intelligence Projects from my COMP3270 course at The University of Hong Kong Topics include intelligent agents search techniques for problem solving knowledge representation logical inference reasoning under uncertainty statistical models and machine learning NOTE Please use Python 3 and not Python 2,2019-02-01T00:48:48Z,2019-02-01T01:24:12Z,Python,priyanksharma7,User,0,1,0,6,master,priyanksharma7#priyanksharma2510,2,0,0,0,0,0,0
bhpfelix,Compositional-Attention-Networks-for-Machine-Reasoning-PyTorch,n/a,CAN PyTorch Work in Progress This is a PyTorch implementation of the Compositional Attention Network architecture introduced in the recent ICLR 2018 paper Drew A Hudson Christopher D Manning Compositional attention networks for machine reasoning International Conference on Learning Representations 2018 https arxiv org abs 1803 03067 This implementation is focused on exploring and re producing the general characteristics of the architecture,2018-03-18T02:14:51Z,2019-11-15T02:28:46Z,Jupyter Notebook,bhpfelix,User,4,18,7,30,master,bhpfelix,1,0,0,2,1,0,0
cosmicBboy,bayesian-reasoning-machine-learning,n/a,bayesian reasoning machine learning Code and notes for Bayesian Reasoning and Machine Learning,2017-10-31T01:55:42Z,2019-12-05T10:05:28Z,Matlab,cosmicBboy,User,1,7,4,2,master,cosmicBboy,1,0,0,0,0,0,0
nie-ine,N3-rule-based_machine-reasoning,n/a,N3 rule based machine reasoning In the NIE INE http www nie ine ch project we develop an infrastructure to enable scholarly edition projects in the Humanities to express their data in an enriched format adhering to the FAIR principles and ensuring long term storage of the data The project runs at the Swiss Universities of Basel Bern Zrich and Geneva until the end of 2020 The essence of the infrastructure is that data stored in e g a MySQL relational database are converted to a different machine readable format i e one that makes the semantics of the data explicit To enable data expression in this new format a series of vocabularies or ontologies https github com nie ine Ontologies are created representing Semantic Web technology https github com nie ine Ontologies wiki 1 Introduction to Semantic Web technology Besides these ontologies rules for machine resoning are developed They are expressed in the Notation 3 language https www w3 org TeamSubmission n3 also using elements of NIE and external ontologies Notation 3 is an assertion and logic language which is a superset of RDF N3 extends the RDF datamodel by adding formulae literals which are graphs themselves variables logical implication and functional predicates as well as providing a textual syntax alternative to RDF XML In this way Turtle is a subset of N3 The general external ontologies for N3 rule declaration are in following namespaces They provide class and property declarations for built ins representing an extensive variety of functionalities These built ins are mentioned in some of the following rule examples N3 rules serve different purposes Note also mentioned in the use case catalogue Implementation of the RDF model theory A set of N3 rules implementating of the RDF model theory https github com josd eye tree master reasoning rpo permits to infer data from data based on the built in logic of the W3C Semantic Web standard languages Examples are rules for the implementation of prefix rdfs prefix owl rdfs subClassOf rdfs subPropertyOf owl TransitiveProperty owl disjointWith owl oneOf owl unionOf owl disjointUnionOf owl propertyChainAxiom A complete reasoning example on transitivity for the is part of property for text and text structures as prosodic entities is given in the repository also involving a series of other RDFS and OWL rules The data and query files are commented Consistency check for user defined restrictions User defined restrictions can be checked upon e g a cardinality restriction for the object value of a certain property of a certain subject class instance Figure 1 shows part of the human class declaration in Turtle with a cardinality restriction of maximum 1 on the property has biological sex IOW a human can only have exactly 1 biological sex i e female male or intersexual see human ontology https github com nie ine Ontologies blob master Nie ontologies Generic ontologies human ontology ttl prefix human human Human rdfs subClassOf a owl Restriction owl onProperty human hasBiologicalSex owl maxCardinality 1 xs nonNegativeInteger Figure 1 Class declaration with a cardinality restriction of maximum 1 A reasoning example on cardinality is given in the repository using 2 external ontologies and an RDF data set on images of the Knora server application https www knora org developed by the DHLab DHL https dhlab philhist unibas ch en home at the University of Basel and the Data and Service Center for humanities DaSCH https dasch swiss Temporal reasoning Generally time indicators are uniformly converted to intervals to calculate with For this process the machine reasoner provides an extensive set of Time and RIF Built ins https raw githubusercontent com josd eye master eye builtins n3 based on W3C standards RIF Datatypes and Built Ins 1 0 https www w3 org TR 2013 REC rif dtb 20130205 using for instance literals typed with e g xs dateTime and xs duration from the namespace Further functionality is provided by the time ontology https raw githubusercontent com nie ine Ontologies master Nie ontologies Generic ontologies time ontology ttl declaring the properties used in N3 rules A temporal reasoning example is given in the repository considering an event without a start or end date with specific example of missing birth or death date Miscellaneous functionalities and calculations Also for this type of N3 rules a large set of built ins https raw githubusercontent com josd eye master eye builtins n3 is available dealing with e g logical and mathematical operators lists and strings For example string manipulation e g parsing using regular expressions is possible with formal expressions offering the advantage of staying in the formal N3 RDF environment until a fully reasoned upon data set or deductive closure is obtained which can be stored in an RDF database and queried with SPARQL or which can be transformed to JSON LD for GUI application The repository contains a reasoning example on sequence numbers or ordinals derived from entity identifiers using following properties declared in the respective ontology prefix math math hasSequenceLiteral math hasSequenceNumeral and a set of rules that can be made as general as possible but very likely only within a certain project considering the numerous possible combinations in creating alphanumeric identifiers Machine Reasoner EYE Euler Yet another proof Engine Development https github com josd eye Download site https sourceforge net projects eulersharp files eulersharp EYE comes with syntax check and intrinsic functionality provided by built ins https github com josd eye blob master eye builtins n3 All other reasoning material has to be input i e OWL ontologies RDF data N3 rules Basic command example for EYE Note the command for the reasoner is written for Unix OS but can be easily converted for Windows OS eye call the machine reasoner one or more options can be used e g nope option for output without a proof traditional option for N3 syntax e g prefix instead of PREFIX local or remote references can be added to assert ontology data or rule graphs rdf data ttl ref to one or more RDF data sets expressed in Turtle syntax ttl subset of N3 ttl can be replaced by n3 owl ontology ttl ref to one or more OWL ontologies expressed in OWL Full or lesser sublanguage using all possible elements of RDF S OWL ontologies rule n3 ref to one or more N3 rules EYE is a stateless reasoner meaning that all inferencing formalisms have to be fed to it output as a pass OR an N3 query pass output deductive closure all the stated and inferred triples except the rules pass all output deductive closure plus rules query output filtered with N3 query output can be written to a file result n3 result file,2017-05-18T08:43:54Z,2019-12-03T00:29:37Z,Shell,nie-ine,Organization,5,2,0,5,master,janCstoffregen#hanscools,2,0,0,0,0,0,0
usptact,PrinterNightmare,bayesian-inference#probabilistic-programming,PrinterNightmare Printer Nightmare Belief Network from D Barber Bayesian Reasoning and Machine Learning The demo shows how to 1 Learn model parameters from data issue and component state history 2 Query trained model The model is trained from 15 visits of a repairmen to CheapCo The query infers the probability of Fuse Assembly fault given that Burning smell and Paper Jam is observed no other issues Updated to use open source Infer NET,2017-10-31T21:02:41Z,2018-11-19T08:47:17Z,C#,usptact,User,1,1,0,3,master,usptact,1,0,0,0,0,0,0
louilinn,Artificial_Intelligence_Projects,n/a,This repository contains three projects 1 An AI playing Othello aka Reversi 2 Machine Learning logistic regression induction of decision trees 3 Probabilistic reasoning over time,2017-02-03T15:46:54Z,2018-12-03T13:21:59Z,Jupyter Notebook,louilinn,User,1,1,0,9,master,louilinn#mirrish,2,0,0,0,0,0,0
Lyyoness,CS50-51---Formal-Analysis,n/a,404 Not Found,2018-02-18T10:44:06Z,2018-04-02T13:09:24Z,Jupyter Notebook,Lyyoness,User,0,1,0,1,master,Lyyoness,1,0,0,0,0,0,0
kavashashank,INST728Q-Visual_Analytics,n/a,INST728Q VisualAnalytics The course consists of special topics experimental course on Visual Analytics in Spring 2016 Visual analytics is the use of interactive visual interfaces to facilitate analytical reasoning In essence visual analytics is based on thenot uncontroversialidea that humans and computers working alone are insufficient for the data challenges of today and tomorrow and that effective synthesis of both humans and computational algorithms are needed to create human in the loop systems Thus visual analytics bridges human centered disciplines such as visualization and human computer interaction with computation centered disciplines such as machine learning probabilistic methods and knowledge discovery In this course intended for iSchool graduate students but open to any masters or Ph D student at UMD you will learn how to apply these exciting techniques to practical problems and work on state of the art research projects that could lead to a publication in one of the prestigious IEEE VIS conferences After taking this course students will be able to Understand human aspects such as perception cognition sensemaking critical thinking and the analytical process Understand computational aspects such as data management data transformations knowledge representation probabilistic methods and text analytics etc Synthesize knowledge from fields such as visualization human computer interaction machine learning knowledge discovery and text analytics towards helping people understand data Use existing visual analytics tools to analyze basic datasets,2017-11-04T00:45:02Z,2018-05-02T17:51:38Z,Jupyter Notebook,kavashashank,User,2,1,2,3,master,kavashashank,1,0,0,0,0,0,0
djour,PyBRML,n/a,SOCIS 2013 Proposal Framework construction and application to real world inference problem The goal of this project would be to implement an efficient and object oriented framework for Python version of BRML toolbox BRML toolbox is developed under MATLAB and offered various demos related to Bayesian Reasoning and Machine Learning The toolbox is affiliated to a recent well designed book by David Barber Reader from Computer Science Department in University College London UCL The significance for our PyBRML work can be emphasized in two ways Bayesian reasoning and probabilistic graphical model is a unified framework for building expert system in order to solve real world problems Currently no actively developing toolbox for bayesian reasoning and probabilistic graphical model under Python exists Our PyBRML would benefits both the book readers engineers and researchers who prefer Python as well The BRML toolbox offered algorithms for various topics such as Bayesian reasoning machine learning dynamic systems and approximate inference etc The current framework in BRML is summarized below https github com pythonroar PyBRML blob master proposal datastructure png In SOCIS 2013 most importantly we will focus on the Bayesian reasoning and probabilistic graphical model section since it provides probabilistic modeling which is fundamental for probabilistic machine learning and dynamical models and further approximate inference Roadmap The First Step of this project is to create a framework for BRML toolbox in Python corresponding to MATLAB version On the Bayesian reasoning and probabilistic graphical model part there are about 10 standalone functions for graph theory 30 for potential manipulation and 20 for inference Thanks to the demos ie demoClouseau demoBurglar demoMRFclean demoMostProbablePath demoShortestPath demoSumprod demoMaxprod demoBucketElim etc offered by BRMLtoolbox we will conduct our implementation based on the demos one by one Finally make the inference algorithms such as factor graph and junction tree accessible for solving problems Further Steps of the project would then consists two directions Develop visualization library for Bayesian reasoning and probabilistic graphical model based on matplotlib library corresponding to miscellaneous functions in BRML toolbox Follow the AAAI00 paper on Bayesian Fault Detection and Diagnosis in Dynamic System make a throughout tutorial on solving real world problems such as engine monitoring and diagnosis Basic Requirements Basic background in machine learning and probabilistic graphical model Former experience with both MATLAB and Python Familiar with basic software engineering techniques such as version control and doctest References The BRML Matlab package manual http web4 cs ucl ac uk staff D Barber textbook brmlpackage pdf Engine Diagnosis paper U Lerner R Parr D Koller and G Biswas Bayesian Fault Detection and Diagnosis in Dynamic Systems In Proceedings of the Seventeenth National Conference on Artificial Intelligence AIII 00 pages 531 537 2000 NASA funding research on diagnostics http ti arc nasa gov tech dash diagnostics and prognostics PyBRML Toolbox PyBRML is a Python version of BRML toolbox for Bayesian Reasoning and Machine Learning Thanks to Dr David Barber s book Bayesian Reasoning and Machine Learning and his original design of the toolbox as an accompanying code for the book Book Bayesian Reasoning and Machine Learning http web4 cs ucl ac uk staff D Barber textbook jacket gif BOOKbarberBRML2012 author Barber D title Bayesian Reasoning and Machine Learning publisher Cambridge University Press year 2012 website for the book http www cs ucl ac uk staff d barber brml Motivation from David The BRMLtoolbox is provided to help readers see how mathematical models translate into actual MAT LAB code There are a large number of demos that a lecturer may wish to use or adapt to help illustrate the material In addition many of the exercises make use of the code helping the reader gain confidence in the concepts and their application Along with complete routines for many Machine Learning methods the philosophy is to provide low level routines whose composition intuitively follows the mathematical description of the algorithm In this way students may easily match the mathematics with the corresponding algorithmic implementation History Former MATLAB implementation of BRML Toolbox include Object Oriented Version OO Older non OO Check these two version from Dr David Barber s Homepage http web4 cs ucl ac uk staff D Barber pmwiki pmwiki php n Brml Software Contribution The source code is hosted on GitHub and comments suggestions and contributions are welcomed If you use BRML toolbox in your work please cite the reference book License The Python version of BRML toolbox library is available under a GNU license Bundled dependencies Numpy matplotlib Documentation Under construction Community Under construction Reference BOOKbarberBRML2012 author Barber D title Bayesian Reasoning and Machine Learning publisher Cambridge University Press year 2012,2013-06-09T07:51:51Z,2019-12-10T12:44:45Z,Python,djour,User,18,142,41,37,master,djour#MingjunZhou,2,0,0,0,0,0,1
Edderic,BRML-non-OOP,n/a,Please run setup m help Contents displays list of the files There are bugs in the Matlab JIT compiler that may prevent the code working correctly Setup m will turn off the JIT compiler if it detects a bug Setup also adds the graphlayout package from A T Cemgil to the path See LICENSE txt for the license David Barber davidobarber gmail com Department of Computer Science University Collge London November 2008,2015-08-06T23:17:35Z,2019-11-05T11:26:12Z,Matlab,Edderic,User,1,14,5,63,master,Edderic,1,0,0,0,0,0,0
taheris,BRML.jl,n/a,Getting started A working installation of Julia version 0 2 or greater is required which can be downloaded from here http julialang org downloads As NumPy and SciPy from Python are also dependencies a working Python installation along with these libraries are required If these are not yet available the easiest way to get them is to install the Anaconda software which can be downloaded here http www continuum io downloads or they can be installed manually otherwise To start the Julia REPL run the julia binary from a console julia A fresh approach to technical computing Documentation http docs julialang org Type help to list help topics Version 0 2 0 2643 rbab3d1e3d Commit bab3d1e3d 2013 07 15 23 12 09 x8664 unknown linux gnu julia To get the latest list of Julia packages run the Pkg update command julia Pkg update As the toolbox is still in development this package and its dependencies will need to be retrieved manually from this repository To do so change directory to the Julia package directory at the command line This will be located at julia for Linux and OS X or APPDATA julia packages for Windows by default From the package directory issue the following command git clone https github com taheris BRML jl git From the Julia REPL issue another Pkg update command from to retrieve the toolbox dependencies After this issue the following command to import the package julia using BRML Following that command the BRML package has now been imported into the current Julia environment and is ready to use In future Julia sessions only this command needs to be issued to make the BRML toolbox available,2013-09-02T16:29:36Z,2019-07-25T20:05:38Z,Matlab,taheris,User,2,12,4,3,master,taheris#Edderic,2,0,0,0,1,0,1
codenameyau,inference-engine,n/a,inference engine Reasoning machine built with node Running the demo 1 Clone this repo 2 Run npm install 3 Run node app main js Sample demo Welcome to the inference engine demo Type help for help all dogs are mammals Okay all cats are mammals Okay all mammals are hairy animals Okay all hairy animals are animals Okay all birds are animals Okay are all dogs animals true are all dogs cats false are all birds cats false are all animals birds false,2014-12-10T21:59:37Z,2017-10-20T00:25:28Z,JavaScript,codenameyau,User,1,10,1,35,master,codenameyau,1,0,0,0,0,0,0
MyCSHome,Machine-Learning-Implementations,n/a,code for Imperial College C395 class implemented decision tree neural network case based reasoning and statistical test,2013-02-28T10:31:53Z,2014-07-13T16:18:11Z,Matlab,MyCSHome,User,2,3,6,4,master,MyCSHome,1,0,0,0,0,0,0
iliasfotopoulos,machine-translator,n/a,Machine Translator Machine translation of numbers in words from greek to english and vice versa using Prolog for NTUA http www ece ntua gr en Knowledge Representation and Reasoning Course Assignment summary Goal of the assignment is to translate numbers written in words from a natural language to another For example a hundred ninety three six hundred twelve cent quatre vingt treize six cents douze ein Hundert drei und neunzig sechs Hundert zwoelf Natural Language Parser Design a natural language machine translator that takes as input a number from zero to nine hundred and ninety nine in a Language A and translates it to an other Language B and vice versa Examples a hundred ein Hundert treize quatorze quinze thirteen fourteen fifteen quatre vingt quatre vingt dix six hundred Programming Enviroment Usage of DCG definite clause grammar using GULP 3 1 http www cs toronto edu dianaz 2501 Parser gulp3mod pl Prolog extension for Unification Based Grammar,2014-10-12T07:48:39Z,2014-12-18T20:27:49Z,Prolog,iliasfotopoulos,User,1,1,0,19,master,iliasfotopoulos,1,0,0,0,0,0,0
